{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requesting Anophelines Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original data contain different species of Anophelines. Due to time limit, we only train study the specific species __Anophelines Funestus__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#the data can be downloaded from https://www.kaggle.com/jboysen/malaria-mosquito\n",
    "# We have eliminated the data before 1990 due to the limit of available climate data\n",
    "original_data=pd.read_csv('data/Anophelines.csv', engine='python')\n",
    "original_data=original_data.loc[original_data['YeStart']>1990]\n",
    "print(original_data.shape)\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=original_data[['Full_Name','Lat','Long','YeStart','YeEnd','An funestus  s.l']]\n",
    "\n",
    "# In the original data, Y means occurrence\n",
    "# We formulate the problem as a binary classification problem\n",
    "# Replace all 'Y' with 1, and all 'Nan' with 0\n",
    "mapping={'Y':1}\n",
    "data=df.replace({'An funestus  s.l':mapping,'An gambiae ss':mapping})\n",
    "data=data.fillna(0)\n",
    "data=data.rename(columns={'An funestus  s.l':'Funestus'})\n",
    "data.to_csv('Mosquitoes.csv',index=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to time limit, our climate features conssist of __[monthly minimum temperatures, monthly maximum temperatures]__. More climate features can be added in the future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['min','max']:\n",
    "  for i in range(12):\n",
    "    data[f'{feature}_{i+1}']=''\n",
    "  \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requesting Climate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the preparion, now we should add climate data. For each row of _data_ , we request and compute monthly minimum temperatures and monthly maximum temperatures, the number of features is 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from ibmpairs import paw, authentication\n",
    "from geopandas import GeoDataFrame\n",
    "import numpy as np\n",
    "\n",
    "def get_min_temp(lat,long,end_year):\n",
    "  PAIRS_API_KEY = '1FkApXtW3DHJWYPRLIFLWkhmADLiKFhe2uNOclT1CoU' \n",
    "  PAIRS_SERVER   = 'https://pairs.res.ibm.com'\n",
    "  PAIRS_CREDENTIALS = authentication.OAuth2(api_key = PAIRS_API_KEY)\n",
    "  query_json = {\n",
    "    \"layers\" : [\n",
    "      {\"type\" : \"raster\", \"id\" : \"49429\"}\n",
    "    ],\n",
    "    \"spatial\" : {\"type\" : \"point\", \"coordinates\" : [f\"{lat}\", f\"{long}\"]},\n",
    "    \"temporal\" : {\"intervals\" : [\n",
    "      {\"start\" : f\"{end_year-1}-01-01T00:00:00Z\", \"end\" : f\"{end_year}-01-01T00:00:00Z\"}\n",
    "    ]}\n",
    "  }\n",
    "  query = paw.PAIRSQuery(query_json, PAIRS_SERVER, PAIRS_CREDENTIALS, authType='api-key')\n",
    "  try:\n",
    "    query.submit()\n",
    "  except:\n",
    "    return [np.nan]*12\n",
    "  df=query.vdf\n",
    "  df=df[['timestamp','value']]\n",
    "  # return df\n",
    "  temp_month=[None]*12\n",
    "  for month in range(12):\n",
    "    temp_month[month]=[]\n",
    "  for idx in range(df.shape[0]):\n",
    "    month=df.iloc[idx]['timestamp'].month\n",
    "    temp_month[month-1].append(df.iloc[idx]['value']-273.15)\n",
    "  if all(list(map(len,temp_month))):\n",
    "    return list(map(min,temp_month))\n",
    "  else:\n",
    "    return [np.nan]*12\n",
    "    \n",
    "\n",
    "def get_max_temp(lat,long,end_year):\n",
    "  PAIRS_API_KEY = '1FkApXtW3DHJWYPRLIFLWkhmADLiKFhe2uNOclT1CoU' # Put your API key here. Important: Best practice is not to include secrets in source code.\n",
    "  PAIRS_SERVER   = 'https://pairs.res.ibm.com'\n",
    "  PAIRS_CREDENTIALS = authentication.OAuth2(api_key = PAIRS_API_KEY)\n",
    "  query_json = {\n",
    "    \"layers\" : [\n",
    "      {\"type\" : \"raster\", \"id\" : \"49430\"}\n",
    "    ],\n",
    "    \"spatial\" : {\"type\" : \"point\", \"coordinates\" : [f\"{lat}\", f\"{long}\"]},\n",
    "    \"temporal\" : {\"intervals\" : [\n",
    "      {\"start\" : f\"{end_year-1}-01-01T00:00:00Z\", \"end\" : f\"{end_year}-01-01T00:00:00Z\"}\n",
    "    ]}\n",
    "  }\n",
    "  query = paw.PAIRSQuery(query_json, PAIRS_SERVER, PAIRS_CREDENTIALS, authType='api-key')\n",
    "  try:\n",
    "    query.submit()\n",
    "  except:\n",
    "    return [np.nan]*12\n",
    "  df=query.vdf\n",
    "  df=df[['timestamp','value']]\n",
    "  # return df\n",
    "  temp_month=[None]*12\n",
    "  for month in range(12):\n",
    "    temp_month[month]=[]\n",
    "  for idx in range(df.shape[0]):\n",
    "    month=df.iloc[idx]['timestamp'].month\n",
    "    temp_month[month-1].append(df.iloc[idx]['value']-273.15)\n",
    "  if all(list(map(len,temp_month))):\n",
    "    return list(map(max,temp_month))\n",
    "  else:\n",
    "    return [np.nan]*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERA5 A global reanalysis data set produced by ECMWF, the European Centre for Medium-Range Weather Forecasts.\n",
    "# ERA5 is the direct successor to the ERA Interim reanalysis.\n",
    "# It provides global, hourly data at a resolution of 0.25 by 0.25 degrees.\n",
    "\n",
    "# use the following line if you want to continue from where you pause\n",
    "# for i in range(503,data.shape[0]):\n",
    "for i in range(data.shape[0]):\n",
    "  element=data.iloc[i]\n",
    "  lat=element['Lat']\n",
    "  long=element['Long']\n",
    "  end_year=element['YeEnd']\n",
    "  min_temp=get_min_temp(lat,long,end_year)\n",
    "  for month in range(12):\n",
    "    data.at[i,f'min_{month+1}']=min_temp[month]\n",
    "  min_temp=get_max_temp(lat,long,end_year)\n",
    "  for month in range(12):\n",
    "    data.at[i,f'max_{month+1}']=min_temp[month]\n",
    "    \n",
    "  # store intermediate data, in case of interrupt\n",
    "  if i%50==0:\n",
    "    print(f'{i}\\{data.shape[0]}')\n",
    "    print('-'*20)\n",
    "    data.to_csv(f'data_ERA5/data_{i}.csv',index=False)\n",
    "# final result\n",
    "\n",
    "# Some locations'[latitude and longitude] climate data are not available. And these features are NaN\n",
    "# We need to drop all rows containning NaN\n",
    "data.dropna(inplace=True)\n",
    "data.to_csv('data_ERA5/data.csv',index=False)\n",
    "#split the data to train_data and test_data\n",
    "train_data=data.iloc[range(4000)]\n",
    "test_data=data.iloc[range(4000,data.shape[0])]\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
